#import dataset
dataset <- read_excel('Book.xlsx', dec = ",")
library(readxl)
library(dplyr)
library(writexl)
#import dataset
#dataset <- read_excel('Book.xlsx', dec = ",")
dataset <- read.csv("Book.xlsx", stringsAsFactors = FALSE)
class(dataset$Probes)
class(dataset$`Gene Symbol`)
class(dataset$hsa_mirbase)
class(dataset$`UTSW#01-IC`)
#dataset
dataset[] <- lapply(dataset, function(x) as.numeric(as.character(x)))
library(readxl)
library(dplyr)
library(writexl)
#import dataset
dataset <- read_excel('Book.xlsx')
class(dataset$Probes)
class(dataset$`Gene Symbol`)
class(dataset$hsa_mirbase)
class(dataset$`UTSW#01-IC`)
dataset[] <- lapply(dataset, function(x) {
if (is.character(x)) {
# Only apply the transformation to character columns
return(as.numeric(gsub(",", ".", x)))
} else {
# Leave non-character columns as is
return(x)
}
})
#dataset
#dataset[] <- lapply(dataset, function(x) as.numeric(as.character(x)))
dataset[] <- lapply(dataset, function(x) {
if (is.numeric(x)) x[is.nan(x)] <- NA  # Convert NaN to NA
return(x)
})
sum(is.nan(as.matrix(dataset)))
#dataset <- na.omit(dataset)
#remove columns containing NAs
#define new data frame
new_daset <- dataset[, colSums(is.na(dataset)) == 0]
#view new data frame
new_daset
dim(dataset)
dim(new_daset)
#verify that all NA values have been removed
sum(is.na(new_daset))
colSums(is.na(new_daset))
# Export the cleaned dataset to an Excel file
write_xlsx(new_daset, "cleaned_dataset.xlsx")
library(openxlsx)
library(dplyr)
library(writexl)
#import dataset
dataset <- read.xlsx('Book.xlsx')
class(dataset$Probes)
class(dataset$`Gene Symbol`)
class(dataset$hsa_mirbase)
class(dataset$`UTSW#01-IC`)
dataset[] <- lapply(dataset, function(x) {
if (is.character(x)) {
# Only apply the transformation to character columns
return(as.numeric(gsub(",", ".", x)))
} else {
# Leave non-character columns as is
return(x)
}
})
#dataset
#dataset[] <- lapply(dataset, function(x) as.numeric(as.character(x)))
dataset[] <- lapply(dataset, function(x) {
if (is.numeric(x)) x[is.nan(x)] <- NA  # Convert NaN to NA
return(x)
})
sum(is.nan(as.matrix(dataset)))
#dataset <- na.omit(dataset)
#remove columns containing NAs
#define new data frame
new_daset <- dataset[, colSums(is.na(dataset)) == 0]
#view new data frame
new_daset
dim(dataset)
dim(new_daset)
#verify that all NA values have been removed
sum(is.na(new_daset))
colSums(is.na(new_daset))
library(readxl)
library(dplyr)
library(writexl)
#import dataset
dataset <- read_excel('Book.xlsx')
class(dataset$Probes)
class(dataset$`Gene Symbol`)
class(dataset$hsa_mirbase)
class(dataset$`UTSW#01-IC`)
dataset[] <- lapply(dataset, function(x) {
if (is.character(x)) {
# Only apply the transformation to character columns
return(as.numeric(gsub(",", ".", x)))
} else {
# Leave non-character columns as is
return(x)
}
})
#dataset
#dataset[] <- lapply(dataset, function(x) as.numeric(as.character(x)))
dataset[] <- lapply(dataset, function(x) {
if (is.numeric(x)) x[is.nan(x)] <- NA  # Convert NaN to NA
return(x)
})
sum(is.nan(as.matrix(dataset)))
#dataset <- na.omit(dataset)
#remove columns containing NAs
#define new data frame
new_daset <- dataset[, colSums(is.na(dataset)) == 0]
#view new data frame
new_daset
dim(dataset)
dim(new_daset)
#verify that all NA values have been removed
sum(is.na(new_daset))
colSums(is.na(new_daset))
# Export the cleaned dataset to an Excel file
write_xlsx(new_daset, "cleaned_dataset.xlsx")
library(readxl)
library(dplyr)
library(writexl)
#import dataset
dataset <- read_excel('Book2.xlsx')
class(dataset$Probes)
class(dataset$`Gene Symbol`)
class(dataset$hsa_mirbase)
class(dataset$`UTSW#01-IC`)
dataset[] <- lapply(dataset, function(x) {
if (is.character(x)) {
# Only apply the transformation to character columns
return(as.numeric(gsub(",", ".", x)))
} else {
# Leave non-character columns as is
return(x)
}
})
#dataset
#dataset[] <- lapply(dataset, function(x) as.numeric(as.character(x)))
dataset[] <- lapply(dataset, function(x) {
if (is.numeric(x)) x[is.nan(x)] <- NA  # Convert NaN to NA
return(x)
})
sum(is.nan(as.matrix(dataset)))
#dataset <- na.omit(dataset)
#remove columns containing NAs
#define new data frame
new_daset <- dataset[, colSums(is.na(dataset)) == 0]
#view new data frame
new_daset
dim(dataset)
dim(new_daset)
#verify that all NA values have been removed
sum(is.na(new_daset))
colSums(is.na(new_daset))
# Export the cleaned dataset to an Excel file
write_xlsx(new_daset, "cleaned_dataset.xlsx")
library(readxl)
library(data.table)
library(writexl)
library(oligo)
# Read the Excel file
excel_data <- read_excel("cleaned_dataset.xlsx")
# Convert it to a feature object (data.table)
feature_data <- as.data.table(excel_data)
# View the feature object
head(feature_data)
normalized_data <- rma(feature_data)
install.packages("BiocManager")
BiocManager::install("Biobase")
library(readxl)
#library(data.table)
library(writexl)
library(oligo)
library(Biobase)   # To work with ExpressionSet objects
# Read the Excel file
excel_data <- read_excel("cleaned_dataset.xlsx")
expression_matrix <- as.matrix(excel_data[, -1])  # Remove first column (gene identifiers) for the data matrix
rownames(expression_matrix) <- excel_data[[1]]
feature_info <- data.frame(gene_name = rownames(expression_matrix))  # Example, adapt based on your data
featureData <- AnnotatedDataFrame(feature_info)
eset <- ExpressionSet(assayData = expression_matrix,
featureData = featureData)
eset <- ExpressionSet(expression_matrix = expression_matrix,
featureData = featureData)
excel_data <- read_excel("cleaned_dataset.xlsx")
feature_data <- as.data.table(excel_data)
library(readxl)
library(data.table)
excel_data <- read_excel("cleaned_dataset.xlsx")
feature_data <- as.data.table(excel_data)
normalized_data <- rma(feature_data)
library(readxl)
library(writexl)
input_directory <- "Scaling_output"
for (i in 1:5) {
cat("Processing Fold", i, "\n")
# Load datasets
train_data <- read_excel(file.path(input_directory, paste0("training_scaled_fold_", i, ".xlsx")))
test_data  <- read_excel(file.path(input_directory, paste0("testing_scaled_fold_", i, ".xlsx")))
## === TRAINING SET PROCESSING ===
# Get sample names from column headers
train_sample_names <- colnames(train_data)[-1]  # exclude 'Gene_symbol'
# Get binary status
train_status_binary <- ifelse(grepl("-IIIC$", train_sample_names), 0, 1)
# Transpose training data (excluding Gene_symbol column)
train_data_t <- as.data.frame(t(train_data[-1]))  # removes first column (Gene_symbol)
colnames(train_data_t) <- train_data[[1]]  # set gene symbols as column names
# Add sample name and status columns
train_data_finals <- cbind(Sample = train_sample_names, train_data_t, Node_status = train_status_binary)
train_data_finals$Node_status <- as.factor(train_data_finals$Node_status)
## === TESTING SET PROCESSING ===
test_sample_names <- colnames(test_data)[-1]
test_status_binary <- ifelse(grepl("-IIIC$", test_sample_names), 0, 1)
test_data_t <- as.data.frame(t(test_data[-1]))
colnames(test_data_t) <- test_data[[1]]
test_data_finals <- cbind(Sample = test_sample_names, test_data_t, Node_status = test_status_binary)
test_data_finals$Node_status <- as.factor(test_data_finals$Node_status)
# Save outputs
write_xlsx(train_data_finals, file.path("Adding_column_output_", paste0("training_dataset_final_fold_", i, ".xlsx")))
write_xlsx(test_data_finals,  file.path("Adding_column_output_", paste0("testing_dataset_final_fold_", i, ".xlsx")))
}
library(readxl)
library(writexl)
input_directory <- "Scaling_output"
for (i in 1:5) {
cat("Processing Fold", i, "\n")
# Load datasets
train_data <- read_excel(file.path(input_directory, paste0("training_scaled_fold_", i, ".xlsx")))
test_data  <- read_excel(file.path(input_directory, paste0("testing_scaled_fold_", i, ".xlsx")))
## === TRAINING SET PROCESSING ===
# Get sample names from column headers
train_sample_names <- colnames(train_data)[-1]  # exclude 'Gene_symbol'
# Get binary status
train_status_binary <- ifelse(grepl("-IIIC$", train_sample_names), 0, 1)
# Transpose training data (excluding Gene_symbol column)
train_data_t <- as.data.frame(t(train_data[-1]))  # removes first column (Gene_symbol)
colnames(train_data_t) <- train_data[[1]]  # set gene symbols as column names
# Add sample name and status columns
train_data_finals <- cbind(Sample = train_sample_names, train_data_t, Node_status = train_status_binary)
train_data_finals$Node_status <- as.factor(train_data_finals$Node_status)
## === TESTING SET PROCESSING ===
test_sample_names <- colnames(test_data)[-1]
test_status_binary <- ifelse(grepl("-IIIC$", test_sample_names), 0, 1)
test_data_t <- as.data.frame(t(test_data[-1]))
colnames(test_data_t) <- test_data[[1]]
test_data_finals <- cbind(Sample = test_sample_names, test_data_t, Node_status = test_status_binary)
test_data_finals$Node_status <- as.factor(test_data_finals$Node_status)
# Save outputs
write_xlsx(train_data_finals, file.path("Adding_column_output", paste0("training_dataset_final_fold_", i, ".xlsx")))
write_xlsx(test_data_finals,  file.path("Adding_column_output", paste0("testing_dataset_final_fold_", i, ".xlsx")))
}
setwd("/Users/sandra/Desktop/thesis/Thesis-project")
library(readxl)
library(writexl)
input_directory <- "Scaling_output"
for (i in 1:5) {
cat("Processing Fold", i, "\n")
# Load datasets
train_data <- read_excel(file.path(input_directory, paste0("training_scaled_fold_", i, ".xlsx")))
test_data  <- read_excel(file.path(input_directory, paste0("testing_scaled_fold_", i, ".xlsx")))
## === TRAINING SET PROCESSING ===
# Get sample names from column headers
train_sample_names <- colnames(train_data)[-1]  # exclude 'Gene_symbol'
# Get binary status
train_status_binary <- ifelse(grepl("-IIIC$", train_sample_names), 0, 1)
# Transpose training data (excluding Gene_symbol column)
train_data_t <- as.data.frame(t(train_data[-1]))  # removes first column (Gene_symbol)
colnames(train_data_t) <- train_data[[1]]  # set gene symbols as column names
# Add sample name and status columns
train_data_finals <- cbind(Sample = train_sample_names, train_data_t, Node_status = train_status_binary)
train_data_finals$Node_status <- as.factor(train_data_finals$Node_status)
## === TESTING SET PROCESSING ===
test_sample_names <- colnames(test_data)[-1]
test_status_binary <- ifelse(grepl("-IIIC$", test_sample_names), 0, 1)
test_data_t <- as.data.frame(t(test_data[-1]))
colnames(test_data_t) <- test_data[[1]]
test_data_finals <- cbind(Sample = test_sample_names, test_data_t, Node_status = test_status_binary)
test_data_finals$Node_status <- as.factor(test_data_finals$Node_status)
# Save outputs
write_xlsx(train_data_finals, file.path("Adding_column_output", paste0("training_dataset_final_fold_", i, ".xlsx")))
write_xlsx(test_data_finals,  file.path("Adding_column_output", paste0("testing_dataset_final_fold_", i, ".xlsx")))
}
test_data_finals[1]
# Load required libraries
library(readxl)
library(writexl)
library(tidymodels)
library(glmnet)
library(caret)
# Hyperparameter grids
penalty <- c(0, 0.5, 1)
mixture <- c(0, 0.5, 1)
total_models_lr <- length(penalty) * length(mixture)
# Prepare results list
performance_all_folds <- list()
for (fold in 1:5) {
cat("Running Fold", fold, "\n")
# === Load data ===
train_data_final <- read_excel(paste0("Adding_column_output/training_dataset_final_fold_", fold, ".xlsx"))
test_data_final  <- read_excel(paste0("Adding_column_output/testing_dataset_final_fold_", fold, ".xlsx"))
# Convert to data.frame
train_data_final <- as.data.frame(train_data_final)
test_data_final  <- as.data.frame(test_data_final)
# Drop Sample column
train_data_final$Sample <- NULL
test_data_final$Sample <- NULL
# Ensure factor type for outcome
train_data_final$Node_status <- as.factor(train_data_final$Node_status)
test_data_final$Node_status  <- as.factor(test_data_final$Node_status)
# Rename for modeling (optional, but matches your original code)
colnames(train_data_final)[colnames(train_data_final) == "Node_status"] <- "Label"
colnames(test_data_final)[colnames(test_data_final) == "Node_status"] <- "Label"
# Performance list for current fold
performance_list_log_reg <- list()
for (i in 1:length(penalty)) {
for (j in 1:length(mixture)) {
# Fit model
model <- logistic_reg(penalty = penalty[i], mixture = mixture[j]) %>%
set_engine("glmnet") %>%
set_mode("classification") %>%
fit(Label ~ ., data = train_data_final)
# Predict
predictions <- predict(model, new_data = test_data_final)
# Confusion matrix
cm <- confusionMatrix(data = predictions$.pred_class, reference = test_data_final$Label)
# Save performance
performance <- list(
fold = fold,
penalty = penalty[i],
mixture = mixture[j],
accuracy = cm$overall[["Accuracy"]],
sensitivity = cm$byClass[["Sensitivity"]],
specificity = cm$byClass[["Specificity"]],
balanced_accuracy = cm$byClass[["Balanced Accuracy"]]
)
performance_list_log_reg[[length(performance_list_log_reg) + 1]] <- performance
}
}
# Store for this fold
performance_all_folds[[fold]] <- performance_list_log_reg
}
# === Extract and summarize all performances ===
all_performance_flat <- do.call(rbind, lapply(performance_all_folds, function(fold_perf) {
do.call(rbind, lapply(fold_perf, as.data.frame))
}))
# View results
print(all_performance_flat)
# Plot Balanced Accuracy
library(ggplot2)
ggplot(all_performance_flat, aes(x = interaction(fold, penalty, mixture), y = balanced_accuracy)) +
geom_point() +
labs(x = "Model (Fold, Penalty, Mixture)", y = "Balanced Accuracy", title = "Logistic Regression Performance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Load required libraries
library(readxl)
library(writexl)
library(tidymodels)
library(glmnet)
library(caret)
# Hyperparameter grids
penalty <- c(0, 0.5, 1)
mixture <- c(0, 0.5, 1)
total_models_lr <- length(penalty) * length(mixture)
# Prepare results list
performance_all_folds <- list()
for (fold in 1:5) {
cat("Running Fold", fold, "\n")
# === Load data ===
train_data_final <- read_excel(paste0("Adding_column_output/training_dataset_final_fold_", fold, ".xlsx"))
test_data_final  <- read_excel(paste0("Adding_column_output/testing_dataset_final_fold_", fold, ".xlsx"))
# Convert to data.frame
train_data_final <- as.data.frame(train_data_final)
test_data_final  <- as.data.frame(test_data_final)
# Drop Sample column
train_data_final$Sample <- NULL
test_data_final$Sample <- NULL
# Ensure factor type for outcome
train_data_final$Node_status <- as.factor(train_data_final$Node_status)
test_data_final$Node_status  <- as.factor(test_data_final$Node_status)
# Rename for modeling (optional, but matches your original code)
colnames(train_data_final)[colnames(train_data_final) == "Node_status"] <- "Label"
colnames(test_data_final)[colnames(test_data_final) == "Node_status"] <- "Label"
# Performance list for current fold
performance_list_log_reg <- list()
for (i in 1:length(penalty)) {
for (j in 1:length(mixture)) {
# Fit model
model <- logistic_reg(penalty = penalty[i], mixture = mixture[j]) %>%
set_engine("glmnet") %>%
set_mode("classification") %>%
fit(Label ~ ., data = train_data_final)
# Predict
predictions <- predict(model, new_data = test_data_final)
# Confusion matrix
cm <- confusionMatrix(data = predictions$.pred_class, reference = test_data_final$Label)
# Save performance
performance <- list(
fold = fold,
penalty = penalty[i],
mixture = mixture[j],
accuracy = cm$overall[["Accuracy"]],
sensitivity = cm$byClass[["Sensitivity"]],
specificity = cm$byClass[["Specificity"]],
balanced_accuracy = cm$byClass[["Balanced Accuracy"]]
)
performance_list_log_reg[[length(performance_list_log_reg) + 1]] <- performance
}
}
# Store for this fold
performance_all_folds[[fold]] <- performance_list_log_reg
}
# === Extract and summarize all performances ===
all_performance_flat <- do.call(rbind, lapply(performance_all_folds, function(fold_perf) {
do.call(rbind, lapply(fold_perf, as.data.frame))
}))
# View results
print(all_performance_flat)
# Plot Balanced Accuracy
library(ggplot2)
ggplot(all_performance_flat, aes(x = interaction(fold, penalty, mixture), y = balanced_accuracy)) +
geom_point() +
labs(x = "Model (Fold, Penalty, Mixture)", y = "Balanced Accuracy", title = "Logistic Regression Performance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Aggregate performance across folds
library(dplyr)
# Group by penalty & mixture, then average balanced accuracy
summary_performance <- all_performance_flat %>%
group_by(penalty, mixture) %>%
summarise(
mean_balanced_accuracy = mean(balanced_accuracy, na.rm = TRUE),
sd_balanced_accuracy = sd(balanced_accuracy, na.rm = TRUE),
.groups = "drop"
) %>%
arrange(desc(mean_balanced_accuracy))
# Print summary
print(summary_performance)
# Highlight best model
best_model <- summary_performance[1, ]
cat("\nBest performing hyperparameter combination:\n")
print(best_model)
# Load required libraries
library(readxl)
library(writexl)
library(tidymodels)
library(glmnet)
library(caret)
# Hyperparameter grids
penalty <- c(0, 0.5, 1)
mixture <- c(0, 0.5, 1)
total_models_lr <- length(penalty) * length(mixture)
# Prepare results list
performance_all_folds <- list()
for (fold in 1:5) {
cat("Running Fold", fold, "\n")
# === Load data ===
train_data_final <- read_excel(paste0("Adding_column_output/training_dataset_final_fold_", fold, ".xlsx"))
test_data_final  <- read_excel(paste0("Adding_column_output/testing_dataset_final_fold_", fold, ".xlsx"))
# Convert to data.frame
train_data_final <- as.data.frame(train_data_final)
test_data_final  <- as.data.frame(test_data_final)
# Drop Sample column
train_data_final$Sample <- NULL
test_data_final$Sample <- NULL
# Ensure factor type for outcome
train_data_final$Node_status <- as.factor(train_data_final$Node_status)
test_data_final$Node_status  <- as.factor(test_data_final$Node_status)
# Rename for modeling (optional, but matches your original code)
colnames(train_data_final)[colnames(train_data_final) == "Node_status"] <- "Label"
colnames(test_data_final)[colnames(test_data_final) == "Node_status"] <- "Label"
# Performance list for current fold
performance_list_log_reg <- list()
for (i in 1:length(penalty)) {
for (j in 1:length(mixture)) {
# Fit model
model <- logistic_reg(penalty = penalty[i], mixture = mixture[j]) %>%
set_engine("glmnet") %>%
set_mode("classification") %>%
fit(Label ~ ., data = train_data_final)
# Predict
predictions <- predict(model, new_data = test_data_final)
# Confusion matrix
cm <- confusionMatrix(data = predictions$.pred_class, reference = test_data_final$Label)
# Save performance
performance <- list(
fold = fold,
penalty = penalty[i],
mixture = mixture[j],
accuracy = cm$overall[["Accuracy"]],
sensitivity = cm$byClass[["Sensitivity"]],
specificity = cm$byClass[["Specificity"]],
balanced_accuracy = cm$byClass[["Balanced Accuracy"]]
)
performance_list_log_reg[[length(performance_list_log_reg) + 1]] <- performance
}
}
# Store for this fold
performance_all_folds[[fold]] <- performance_list_log_reg
}
# === Extract and summarize all performances ===
all_performance_flat <- do.call(rbind, lapply(performance_all_folds, function(fold_perf) {
do.call(rbind, lapply(fold_perf, as.data.frame))
}))
# View results
print(all_performance_flat)
